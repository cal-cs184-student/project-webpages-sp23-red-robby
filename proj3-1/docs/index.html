<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Isolde Fang, Jakob Sorensen">

<title>Project 3-1: Path Tracer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Project 3-1: Path Tracer</h1>
<p class="subtitle lead">CS 184: Computer Graphics and Imaging, Spring 2023</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Isolde Fang, Jakob Sorensen </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>For this project, we implemented components of a physically-based, pathtracing renderer. This begins with ray generation and the handling of intersections for geometric primtives, including triangles and spheres. For the former, we implemented the efficient Möller-Trumbore algorithm. Then to improve the efficiency of detecting intersections, we implemented a bounding volume heirarchy (BVH), partitioning the primitives based off a heuristic which we demonstrate provides signficant performance improvements. From here, we improve the realism of the images by implementing sophisticated physically-based lighting, including direct lighting and indirect lighting. Lastly, we implement adaptive sampling, which serves to improve performance when colors quickly converge, and increase realism when they do not. Overall, we found the project satisfying. We were amazed at the quality and realism of the images given the relatively simple code (though often became frustrated with the long rendering times).</p>
</section>
<section id="part-1-ray-generation-and-scene-intersection-20-points" class="level2">
<h2 class="anchored" data-anchor-id="part-1-ray-generation-and-scene-intersection-20-points">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<section id="ray-generation-primitive-intersection-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="ray-generation-primitive-intersection-pipeline">Ray Generation, Primitive Intersection Pipeline</h3>
<p>At a high level, we must first have a mechanism for determining which color to assign to each pixel. This is determined by the method <code>PathTracer::raytrace_pixel</code>, which takes a pixel coordinate. It is called for each pixel coordinate. For each each, we take the following steps.</p>
<ul>
<li>We take a number of <em>samples</em> around this pixel. These samples are taken in the unit square that originates at the pixels coordinates. That is, for pixel coordinates <span class="math inline">\((x, y)\)</span>, the square’s upper-right corner is given by <span class="math inline">\((x + 1, y + 1)\)</span>. In other words, we will take samples <span class="math inline">\((x + o_1, y + o_2)\)</span> where <span class="math inline">\(o_1\)</span> and <span class="math inline">\(o_2\)</span> are <em>offsets</em> such that <span class="math inline">\(0 \leq o_1, o_2 \leq 1\)</span>. We use the member variable <code>gridSampler</code>’s method <code>get_sample()</code> to obtain <span class="math inline">\((o_1, o_2)\)</span>.</li>
<li>For each <span class="math inline">\((o_1, o_2)\)</span>, we get <span class="math inline">\((x + o_1, y + o_2)\)</span> and normalize this value by dividing by the screen dimensions. After this, the coordinates are in <em>image space</em>.</li>
<li>These <em>image space</em> coordinates are then passed to <code>Camera::generate_ray</code>, using the <code>camera</code> member variable. This produces the ray from the camera to the given sample coordinate. This is done by transforming the normalized image coordinates to camera space coordinates, then into world space coordinates. Finally, the ray’s direction is normalized (as is required by the implementation).</li>
<li>We then call the function <code>est_radiance_global_illumination</code>, passing the obtained ray, to obtain the color for this particular sample.</li>
<li>This is done <span class="math inline">\(n\)</span> times where <span class="math inline">\(n\)</span> is the number of samples to be taken per pixel (which can be modified by the user of the program).</li>
</ul>
<p>But how do we color the objects in our scene? First, in order to treat all object uniformly, we provide a base class, <code>Primitive</code> from which all scene objects derive. For this project, we fully support spheres (<code>Sphere</code>) and triangles (<code>Triangle</code>). The <code>Primitive</code> class defines virtual methods <code>has_intersection</code> and <code>intersect</code>, which we define for <code>Sphere</code> and <code>Triangle</code>. Then, utilizing polymorphism, we store a list holding objects of type <code>Primitive*</code>, which we iterate through, checking for intersections with our rays, and drawing the primitive if an intersection is found. This process is further expanded in later sections.</p>
</section>
<section id="triangle-intersection-möller-trumbore" class="level3">
<h3 class="anchored" data-anchor-id="triangle-intersection-möller-trumbore">Triangle Intersection: Möller-Trumbore</h3>
<p>As mentioned, we implemented the intersection methods for both <code>Sphere</code> and <code>Triangle</code>. As the former’s implementation is relatively straightforward and typical, we will only describe the latter. To test for a ray’s intersection with a <code>Triangle</code>, we implemented the Möller-Trumbore algorithm. We provide a high level description of this algorithm.</p>
<p>The algorithm first checks if the ray is parallel to the plane on which the triangle lies. This is the only case in which an intersection between the ray and plane is impossible. This is done by first taking the cross product of the ray’s dimension vector and one of the edges of the triangle, then taking the dot product of this value and another of the triangle’s edges, and finally checking if this value is zero. Note that due to floating point inaccuracies, we don’t check against zero directly, but check if the value is <em>close enought to zero</em> (i.e., it is less than <span class="math inline">\(\epsilon\)</span> and greater than <span class="math inline">\(-\epsilon\)</span> where <span class="math inline">\(\epsilon\)</span> is a constant defined to be sufficiently close to zero).</p>
<p>From here, the algorithm solves a system of equations involving two of the barycentric coordinates of the triangle and scalar <span class="math inline">\(t\)</span>, where <span class="math inline">\(t\)</span> defines the intersection point <span class="math inline">\(O + td\)</span> (<span class="math inline">\(O\)</span> being the origin of the ray and <span class="math inline">\(d\)</span> being the direction vector). This is done via Cramer’s rule. We denote the two barycentric coordinates obtained as <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>. Only if these values are non-negative and <em>at most</em> 1 when summed does the ray intersect the triangle. With this verified and <span class="math inline">\(t\)</span> obtained, the Möller-Trumbore algorithm is complete. But we provide an additional check, ensuring <span class="math inline">\(t\)</span> is in the allowed range for the ray (i.e., we check <code>t &gt;= ray.min_t &amp;&amp; t &lt;= ray.max_t</code>).</p>
</section>
<section id="showcase" class="level3">
<h3 class="anchored" data-anchor-id="showcase">Showcase</h3>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t1_cube.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Cube</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t1_cow.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Cow</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t1_teapot.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Teapot</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="part-2-bounding-volume-hierarchy-20-points" class="level2">
<h2 class="anchored" data-anchor-id="part-2-bounding-volume-hierarchy-20-points">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<section id="bvh-construction-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="bvh-construction-algorithm">BVH Construction Algorithm</h3>
<p>We first sort all primitives according to the y-value of their bounding box’s centroid, i.e., for a primitive <code>p</code> of type <code>Primitive*</code> we sort according to <code>p-&gt;get_bbox().centroid().y</code>. This was done once, prior to constructing the BVH. We then construct the BVH using this sorted array of primitives as follows.</p>
<p>Given a range within the list (i.e., a pair of iterators <code>start</code> and <code>end</code>), we first compute the bounding box of the primitives, from which we construct a <code>BVHNode</code>. If the number of primitives does not exceed the maximum leaf size (<code>max_leaf_size</code>), we mark the node as a leaf. Otherwise, the question becomes, <em>how do we determine which iterator ranges to assign to the left and right children</em>? To answer this, we take advantage of the fact that the primitives are sorted. First, we obtain the <em>average</em> of the primitive’s y-values (<code>p-&gt;get_bbox().centroid().y</code>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Then we do a binary search to obtain the first primitive in the range whose y-value is <em>not less than the average</em>. We call this the <em>split point</em> (<code>split</code>) and set the left child’s range as <code>[start, split)</code> and right child’s range as <code>[split, end)</code>. If for whatever reason <code>split</code> is at either end of the range, we evenly divide the range in half, assigning one half to each child.</p>
</section>
<section id="performance-improvements" class="level3">
<h3 class="anchored" data-anchor-id="performance-improvements">Performance Improvements</h3>
<p>To test performance improvement after constructing the BVH via the algorithm described above, we tested rendering times on five scenes with primitives counts ranging from 40,081 to 196,608. We observe massive improvements, ranging from 66x to 2553x. The exact improvements observed are found in the table and graph below. It is of note that the most drastic improvements occur when the scene object is vertically oriented, i.e., when it is much taller than is it wide. We see that <code>beast.dae</code> and <code>CBlucy.dae</code>, both very <em>tall</em> figures, have the most drastic improvements, with the latter being an outlier. The only explanation we could think of is that the model is very favorable to our heuristic.</p>
<table class="table">
<colgroup>
<col style="width: 26%">
<col style="width: 32%">
<col style="width: 15%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>File</th>
<th>Primitive Count</th>
<th>Naive (s)</th>
<th>Our algorithm (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>peter.dae</code></td>
<td>40,018</td>
<td>79.0118</td>
<td>1.1783</td>
</tr>
<tr class="even">
<td><code>maxplank.dae</code></td>
<td>50,081</td>
<td>87.7623</td>
<td>0.8615</td>
</tr>
<tr class="odd">
<td><code>beast.dae</code></td>
<td>64,618</td>
<td>161.4620</td>
<td>0.4</td>
</tr>
<tr class="even">
<td><code>CBlucy.dae</code></td>
<td>133,796</td>
<td>221.7524</td>
<td>0.0868</td>
</tr>
<tr class="odd">
<td><code>blob.dae</code></td>
<td>196,608</td>
<td>337.8134</td>
<td>7.4264</td>
</tr>
</tbody>
</table>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="showcase-1" class="level3">
<h3 class="anchored" data-anchor-id="showcase-1">Showcase</h3>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t2_peter.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><code>peter.dae</code>, 40,018 primitives</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t2_max.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><code>maxplanck.dae</code>, 50,801 primitives</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t2_beast.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><code>beast.dae</code>, 64,618 primitives</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t2_lucy.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><code>CBlucy.dae</code>, 133,796 primitives</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t2_blob.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><code>blob.dae</code>, 196,608 primitives</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="part-3-direct-illumination-20-points" class="level2">
<h2 class="anchored" data-anchor-id="part-3-direct-illumination-20-points">Part 3: Direct Illumination (20 Points)</h2>
<p>In this part, we are adding direct light estimation to our rendering. We have two implementations for the direct lighting function.</p>
<section id="uniform-hemisphere-sampling" class="level4">
<h4 class="anchored" data-anchor-id="uniform-hemisphere-sampling">Uniform hemisphere sampling</h4>
<p>We implemented <code>estimate_direct_lighting_hemisphere()</code>, which estimates the lighting from this intersection coming directly from a light beam by sampling uniformly in a hemisphere.</p>
<p>We have a for loop where we iterate over <code>num_samples</code> times, in each iteration:</p>
<ul>
<li><p>We sample a random <code>wi</code> in the hemisphere(object space) using <code>hemisphereSampler</code>.</p></li>
<li><p>We convert <code>wi</code> to <code>wi_w</code>(world space) using the matrix <code>o2w</code>.</p></li>
<li><p>We generate a new ray that starts at <code>hit_p</code> and extends in the direction of <code>wi_w</code>. Additionally, we offset the origin by <code>wi_w * EPS_F</code> for numeral precision issues.</p></li>
<li><p>If the ray intersects anything, we add the product of reflected emission along the ray, the current surface intersection’s bsdf function, <code>cosine(wi)</code>, and <code>1/2π</code>(pdf of uniform hemisphere sampling) to <code>L_out</code> according to the formula below covered in the lecture.</p></li>
</ul>
<p><img src="formula.png" class="img-fluid" style="width:50.0%"></p>
<p>In the end, we divided <code>L_out</code> by <code>num_samples</code>.</p>
<p>CBspheres_lambertian.dae rendering with uniform hemisphere sampling:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./uniform_hemisphere_spheres_16_8_6.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">16 samples per pixel, 8 samples per light</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./uniform_hemisphere_spheres_64_32_6.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">64 samples per pixel, 32 samples per light</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="importance-sampling" class="level4">
<h4 class="anchored" data-anchor-id="importance-sampling">Importance sampling</h4>
<p>We implemented <code>estimate_direct_lighting_importance()</code>, which estimates the lighting from this intersection coming directly from a light beam using importance sampling. We have a for loop where we iterate over every light beam in <code>scene-&gt;lights</code>, in each iteration:</p>
<ul>
<li><p>If the light is a point source, we only sample once. Otherwise, we sample <code>int(ns_area_light)</code> times.</p></li>
<li><p>We use <code>SceneLight::sample_L()</code> to sample the light beam, which takes a hit point, returns the incoming radiance, and writes to <code>wi</code>(the sampled direction between p and the light source), <code>distToLight</code>(the distance between p and the light source in the wi direction), and <code>pdf</code>(the value of the probability density function evaluated at the wi direction).</p></li>
<li><p>We convert <code>wi</code> to <code>wi_o</code>(object space) using matrix <code>w2o</code>.</p></li>
<li><p>If <code>wi_o.z &lt; 0</code>, we continue since the light is behind the surface at the hit point We generate a new ray that starts <code>hit_p</code> and extends in the direction of <code>wi</code>. We set the <code>max_t</code> of the ray to be <code>distToLight - EPS_F</code>(numeral precision issues). Additionally, we offset the origin by <code>wi_w * EPS_F</code> for numeral precision issues.</p></li>
<li><p>If the ray doesn’t intersect with anything, meaning there are no obstacles on its way to the light, we add the product of the incoming radiance calculated by <code>SceneLight::sample_L()</code>, the current surface intersection’s bsdf function, <code>cosine(wi_o)</code>, and <code>1/pdf</code> to L_out according to the formula mentioned above for uniform hemisphere sampling.</p></li>
</ul>
<p>If the light is not a point source, we divided the accumulation of lights by <code>int(ns_area_light)</code>, and add it to <code>L_out</code>.</p>
<p>Since the logic for when the light is a point source or not is very similar, we have a helper function that extracts most of the logic to make our code cleaner.</p>
<p>Finally, we updated <code>PathTracer::est_radiance_global_illumination()</code> to return <code>(zero_bounce_radiance(r, isect) + one_bounce_radiance(r, isect))</code> to test our implementations.</p>
<p>CBspheres_lambertian.dae rendering with importance sampling:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./importance_sampling_spheres_64_32_6.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">64 samples per pixel, 32 samples per light</figcaption><p></p>
</figure>
</div>
<p>dragon.dae rendering with importance sampling:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./dragon_64_32.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">64 samples per pixel, 32 samples per light</figcaption><p></p>
</figure>
</div>
<p>Below we compare the noise levels with diffrent number of light rays with 1 sample per pixel.</p>
<p>CBbunny.dae rendering with:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_l_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">1 light ray</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_l_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">4 light rays</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_l_16.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">16 light rays</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_l_64.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">64 light rays</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>We observe that the variance decreases linearly with the increase in the number of light rays we are using.</p>
<p>Below we compare the two implementations for the direct lighting function: Uniform hemisphere sampling &amp; Importance sampling.</p>
<p>CBbunny.dae with 16 samples per pixel and 8 samples per light:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="uniform_sphere_bunny_16_8.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Uniform hemisphere sampling</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="importance_sampling_bunny_16_8.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Importance sampling</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>CBbunny.dae with 32 samples per pixel and 16 samples per light:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./uniform_sphere_bunny_32_16.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Uniform hemisphere sampling</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./importance_sampling_bunny_32_16.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Importance sampling</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>CBbunny.dae with 64 samples per pixel and 32 samples per light:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./uniform_sphere_bunny_64_32.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Uniform hemisphere sampling</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./importance_sampling_bunny_64_32.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Importance sampling</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>We observe that importance sampling converges much faster and takes a shorter time to compute. Images rendered using uniform hemisphere sampling are noisier because a large proportion of the sample rays we generated won’t intersect with the light source directly. But for importance sampling, we only sample rays from the light source, which makes the rendering process more efficient and generates better rendering results.</p>
</section>
</section>
<section id="part-4-global-illumination-20-points" class="level2">
<h2 class="anchored" data-anchor-id="part-4-global-illumination-20-points">Part 4: Global Illumination (20 Points)</h2>
<p>Now we want to implement global illumination, which includes both direct and indirect lighting. This will make our rendering results more realistic because we will consider lights bouncing multiple times off different surfaces, and light up areas not directly illuminated by lights.</p>
<p>We implemented <code>PathTracer::at_least_one_bounce_radiance()</code>, which returns the one bounce radiance + radiance from extra bounces at this point. We recursively call <code>PathTracer::at_least_one_bounce_radiance()</code> to simulate extra bounces, and we terminate randomly based on Russian Roulette to avoid infinite recursion.</p>
<p>We first need to make a change to <code>PathTracer::raytrace_pixel()</code> where we initialize the camera rays’ depths as <code>max_ray_depth</code>, which we will use later in our recursion process.</p>
<ul>
<li><p>Specially, we first initialize our <code>L_out</code> to be <code>one_bounce_radiance()</code> and set our Russian Roulette continuation probability to be <code>0.65</code>.</p></li>
<li><p>We terminate if the <code>max_ray_depth &lt;= 1</code>, meaning we terminate when we only want direct illumination.</p></li>
<li><p>We also terminate if Russian Roulette tells us to stop</p></li>
<li><p>If none of the termination conditions are met, we used the current surface intersection’s <code>sample_f()</code>, which takes in a <code>w_out</code> and sample a <code>wi</code> and its corresponding pdf valuer, and returns the evaluation of the BSDF at <code>(w_out, *wi)</code>.</p></li>
<li><p>We converted <code>w_in</code> to <code>w_in_world</code>(world space) using the matrix <code>o2w</code>.</p></li>
<li><p>We generate a new ray that starts at <code>hit_p</code> and extends in the direction of <code>w_in_world</code> with depth set to <code>r.depth - 1</code>. Additionally, we offset the origin by <code>w_in_world * EPS_F</code> for numeral precision issues.</p></li>
<li><p>If the new ray intersects the bvh, we recursively call <code>PathTracer::at_least_one_bounce_radiance()</code> on the new ray. And add the product of the result of the recursion call, the radiance returned by <code>sample_f()</code> calculated above, <code>cosine(w_in)</code>, <code>1/pdf</code>, and <code>1/continue_prob</code>.</p></li>
</ul>
<p>Below are some renderings results with 1024 samples per pixel, 4 samples per light and 4 light rays using global illumination.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bench.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">bench.dae</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./wall-e.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">wall-e.dae</figcaption><p></p>
</figure>
</div>
<p>Below is the comparison of CBspheres_lambertian.dae with only direct illumination and with only indirect illumination with 1024 samples per pixel, 4 samples per light and 4 light rays.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./spheres_direct.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">with only direct illumination</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./spheres_indirect.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">with only indirect illumination</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.</p>
<p>Below we demonstrate the rendering results of CBbunny.dae with max_ray_depth with 1024 samples per pixel, 4 samples per light, different max_ray_depth.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_1024_4_0.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">max_ray_depth = 0</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_1024_4_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">max_ray_depth = 1</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_1024_4_2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">max_ray_depth = 2</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_1024_4_3.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">max_ray_depth = 3</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./bunny_1024_4_100.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">max_ray_depth = 100</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.</p>
<p>Below we compare the rendering of CBspheres_lambertian.dae with different samples per pixel, 4 samples per light and 4 light rays.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_1_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">1 sample per pixel</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_2_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">2 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_4_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">4 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_8_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">8 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_16_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">16 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_64_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">64 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task4_spheres_1024_4_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">1024 samples per pixel</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="part-5-adaptive-sampling-20-points" class="level2">
<h2 class="anchored" data-anchor-id="part-5-adaptive-sampling-20-points">Part 5: Adaptive Sampling (20 Points)</h2>
<p>Now we want to implement adaptive sampling, which helps reduce computations for pixels that converge relatively faster compared to other pixels. So instead of using a fixed, usually high, number of samples per pixel, we will stop the sampling process when the pixel already converged, meaning we will concentrate the samples in more challenging parts of the images.</p>
<p>As for our implementation, in each iteration of the for loop of length <code>ns_aa</code>, we compute the cumulative <code>s1</code> and <code>s2</code>, which are used to calculate the mean and the standard deviation for the computation of <code>I</code> based on the formula below. in <code>raytrace_pixel()</code>, for every <code>samplesPerBatch</code> number of samples, we check if the pixels have converged yet. We implemented a <code>has_converged</code> helper function that helps check if a pixel has converged yet based on the formula below, if <code>I ≤ maxTolerance⋅μ</code>, we will stop the sampling process. Otherwise, we keep sampling until the iteration reaches <code>ns_aa</code>, which is the fixed amount of samples we set.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="./task5_f1.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="./task5_2.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>Below we have the rendering result of CBbunny.dae and its corresponding sample rate image with 2048 samples per pixel, 1 sample per light and max_ray_depth = 5.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t5_bunny.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">CBbunny.dae</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./t5_bunny_rate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">sample rate image of CBbunny.dae</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>Below we have the rendering result of CBspheres_lambertian.dae and its corresponding sample rate image with 2048 samples per pixel, 1 sample per light and max_ray_depth = 5.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task5_sphere.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">CBspheres_lambertian.dae</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./task5_sphere_rate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">sample rate image of CBspheres_lambertian.dae</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="note-on-collaboration" class="level2">
<h2 class="anchored" data-anchor-id="note-on-collaboration">Note on Collaboration</h2>
<p>We collaborated through pair programming over Zoom, though had difficulties as Zoom on Ubuntu (which one of us uses) is unstable and will occasionally crash the graphics driver when screen sharing. We each led a few tasks, which we tried to divide evenly, divided based on our interests. This often meant one person would work on a section partially independently, consulting the other when assistance was needed. Overall, it was a smooth process. The main difficulty was arranging which computers to run the renders on (as they were extremely slow in some cases). We each became more familiar with our work preferences and communication styles.</p>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Constructing the BVH took very little time, but if we wanted to further optimize this process, we could construct a prefix sum array for the primitive’s y-values. This would allow us to compute the average for a range in constant time instead of linear time.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>